
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoeffding Inequality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rd\n",
    "import math\n",
    "from scipy.stats import bernoulli\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coin:\n",
    "    \"\"\"Coin class for representing and flipping coins\"\"\"\n",
    "    \n",
    "    def __init__(self, p=0.5):\n",
    "        \"\"\"Create a new coin\n",
    "        Args:\n",
    "        p (float): Probability of flipping a head 0.0 <= p <= 1.0\n",
    "        \"\"\"\n",
    "        self.p = p\n",
    "    \n",
    "    def flip(self, n=1):\n",
    "        \"\"\"Flip the coin a number of times independently\n",
    "        Args:\n",
    "        n (int): Number of coin flips\n",
    "        Returns: \n",
    "        np.ndarray where each element is either heads (1) or tails (0)  \n",
    "        \"\"\"\n",
    "        return bernoulli.rvs(self.p, size=n)\n",
    "    \n",
    "    @staticmethod\n",
    "    def fraction_of_heads(coin):\n",
    "        \"\"\"Calculate fraction of heads obtained in coin flips\n",
    "        Args:\n",
    "        coin : Coin object\n",
    "        Returns:\n",
    "        Fraction of heads obtained in coin flips (float) \n",
    "        \"\"\"\n",
    "        return np.mean(coin) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coins:\n",
    "    \"\"\"Coins class for representing and flipping coins\"\"\"\n",
    "    \n",
    "    def __init__(self, N=1, p=0.5):\n",
    "        \"\"\"Create a new coin\n",
    "        Args:\n",
    "        p (float): Probability of flipping a head 0.0 <= p <= 1.0\n",
    "        N (int): Number of coins to create\n",
    "        \"\"\"\n",
    "        self.p = p\n",
    "        self.N = N\n",
    "        self.flips = None\n",
    "    \n",
    "    def flip(self, n=1):\n",
    "        \"\"\"Flip the coins a number of times independently\n",
    "        Args:\n",
    "        n (int): Number of coin flips\n",
    "        Returns: \n",
    "        np.ndarray where each row represents a particular coin and the elements\n",
    "        in each row are either heads (1) or tails (0) \n",
    "        \"\"\"\n",
    "        self.flips = np.stack([Coin(self.p).flip(n) for i in range(0, self.N)])\n",
    "        return self.flips\n",
    "    \n",
    "    def coin_first_head_fraction(self):\n",
    "        \"\"\"Fraction of heads in first coin flipped\n",
    "        Returns: \n",
    "        Fraction of heads for the first coin flipped (float)\n",
    "        \"\"\"\n",
    "        coin = self.flips[0]\n",
    "        return Coin.fraction_of_heads(coin)\n",
    "    \n",
    "    def coin_random_head_fraction(self):\n",
    "        \"\"\"Random coin flipped\n",
    "        Returns: \n",
    "        Fraction of heads for a random coin flipped (float)\n",
    "        \"\"\"\n",
    "        coin = rd.choice(self.flips)\n",
    "        return Coin.fraction_of_heads(coin)\n",
    "    \n",
    "    def coin_min_head_fraction(self):\n",
    "        \"\"\"Fraction of heads in coin with minimum head frequency flipped\n",
    "        Returns: \n",
    "        Fraction of heads for the first coin with the minimum\n",
    "        frequency of heads flipped (float)\n",
    "        \"\"\"\n",
    "        coin = self.flips[np.argmin(self.flips.sum(axis=1), axis=0)]\n",
    "        return Coin.fraction_of_heads(coin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average value of ν_1 is equal to  0.4894\n",
      "The average value of ν_rand is equal to  0.49310000000000004\n",
      "The average value of ν_min is equal to  0.039200000000000006\n"
     ]
    }
   ],
   "source": [
    "nu_1 = np.array([])\n",
    "nu_rand = np.array([])\n",
    "nu_min = np.array([])\n",
    "n_trials = 1000\n",
    "for i in range(0, n_trials):\n",
    "    coins = Coins(N=1000, p=0.5)\n",
    "    coins.flip(n=10)\n",
    "    nu_1 = np.append(nu_1, coins.coin_first_head_fraction())\n",
    "    nu_rand = np.append(nu_rand, coins.coin_random_head_fraction())\n",
    "    nu_min = np.append(nu_min, coins.coin_min_head_fraction())\n",
    "\n",
    "print('The average value of ν_1 is equal to ', np.mean(nu_1))\n",
    "print('The average value of ν_rand is equal to ', np.mean(nu_rand))\n",
    "print('The average value of ν_min is equal to ', np.mean(nu_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPoint:\n",
    "    \"\"\" RandomPoint class for representing and manipulating random n-dimensional coordinates. \"\"\"\n",
    "    \n",
    "    def __init__(self, dim=1, lower=0.0, upper=1.0):\n",
    "        \"\"\" Create a new random point assuming a uniform distribution between the upper and lower bounds. \n",
    "        Args:\n",
    "        dim (int): Dimension.\n",
    "        lower (float): Lower bound.\n",
    "        upper (float): Upper bound.\n",
    "        \"\"\"\n",
    "        self.dim = dim # dimension\n",
    "        self.lower = lower # lower bound\n",
    "        self.upper = upper # upper bound\n",
    "        self.point = np.random.uniform(lower, upper, dim) # point (numpy.ndarray) (half open interval!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetFunction:\n",
    "    \"\"\"TargetFunction class for representing and manipulation random curves in n-dimensional coordinates.\"\"\"\n",
    "    def __init__(self, dim=1, lower=0.0, upper=1.0, line=True):\n",
    "        \"\"\" Create a new random curve assuming a uniform distribution between the upper and lower bounds. \n",
    "        Args:\n",
    "        dim (int): Dimension.\n",
    "        lower (float): Lower bound.\n",
    "        upper (float): Upper bound.\n",
    "        line (bool): True if requesting to draw a line or false to generate the curve x1**2 + x2**2 - 0.6\n",
    "        \"\"\"\n",
    "        self.line = line\n",
    "        \n",
    "        if self.line:\n",
    "            self.points = [RandomPoint(dim, lower, upper) for i in range(0,2)]\n",
    "        \n",
    "    def sign(self, randomPoint):\n",
    "        return np.sign(self.evaluate(randomPoint))\n",
    "        \n",
    "    def evaluate(self, randomPoint): \n",
    "        if self.line:\n",
    "            x_minus_x1  = randomPoint.point[0] - self.points[0].point[0]\n",
    "            y_minus_y1  = randomPoint.point[1] - self.points[0].point[1]\n",
    "            y2_minus_y1 = self.points[1].point[1] - self.points[0].point[1]\n",
    "            x2_minus_x1 = self.points[1].point[0] - self.points[0].point[0]\n",
    "            return x_minus_x1 * y2_minus_y1 - y_minus_y1 * x2_minus_x1\n",
    "        \n",
    "        x1 = randomPoint.point[0] \n",
    "        x2 = randomPoint.point[1] \n",
    "        return x1**2 + x2**2 - 0.6\n",
    "    \n",
    "    def weights(self):\n",
    "        y1_times_x2 = self.points[0].point[1] * self.points[1].point[0]\n",
    "        x1_times_y2 = self.points[0].point[0] * self.points[1].point[1]\n",
    "        y2_minus_y1 = self.points[1].point[1] - self.points[0].point[1]\n",
    "        x2_minus_x1 = self.points[1].point[0] - self.points[0].point[0] \n",
    "        \n",
    "        return np.array([y1_times_x2 - x1_times_y2, y2_minus_y1, -x2_minus_x1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomLine:\n",
    "    \"\"\" RandomLine class for representing and manipulating random lines in n-dimensional coordinates. \"\"\"\n",
    "    \n",
    "    def __init__(self, dim=1, lower=0.0, upper=1.0):\n",
    "        \"\"\" Create a new random line assuming a uniform distribution between the upper and lower bounds. \n",
    "        Args:\n",
    "        dim (int): Dimension.\n",
    "        lower (float): Lower bound.\n",
    "        upper (float): Upper bound.\n",
    "        \"\"\"        \n",
    "        self.points = [RandomPoint(dim, lower, upper) for i in range(0,2)] # inputs (list(RandomPoint))\n",
    "    \n",
    "    def target_function(self, randomPoint):\n",
    "        \"\"\" Evaluate target function using equation of line in symmetric form.\n",
    "        https://math.stackexchange.com/questions/274712/calculate-on-which-side-of-a-straight-line-is-a-given-point-located.\n",
    "        https://en.wikipedia.org/wiki/Linear_equation.\n",
    "        Args:\n",
    "        randomPoint (RandomPoint): Random point.\n",
    "        Returns: \n",
    "        int. +1 for the point being above the line. -1 for the point being below the line. 0 otherwise.     \n",
    "        \"\"\"\n",
    "        x_minus_x1  = randomPoint.point[0] - self.points[0].point[0]\n",
    "        y_minus_y1  = randomPoint.point[1] - self.points[0].point[1]\n",
    "        y2_minus_y1 = self.points[1].point[1] - self.points[0].point[1]\n",
    "        x2_minus_x1 = self.points[1].point[0] - self.points[0].point[0]\n",
    "        \n",
    "        return np.sign(x_minus_x1 * y2_minus_y1 - y_minus_y1 * x2_minus_x1)\n",
    "    \n",
    "    def weights(self):\n",
    "        \"\"\" Evaluate weights of equation of line in symmetric form, i.e. w0 * x0 + w1 * x1 + w2 * x2 = 0\n",
    "        https://math.stackexchange.com/questions/274712/calculate-on-which-side-of-a-straight-line-is-a-given-point-located.\n",
    "        https://en.wikipedia.org/wiki/Linear_equation.\n",
    "        Returns: \n",
    "        np.ndarray consisting of weights of the line [w0, w1, w2]    \n",
    "        \"\"\"\n",
    "        y1_times_x2 = self.points[0].point[1] * self.points[1].point[0]\n",
    "        x1_times_y2 = self.points[0].point[0] * self.points[1].point[1]\n",
    "        y2_minus_y1 = self.points[1].point[1] - self.points[0].point[1]\n",
    "        x2_minus_x1 = self.points[1].point[0] - self.points[0].point[0] \n",
    "        \n",
    "        return np.array([y1_times_x2 - x1_times_y2, y2_minus_y1, -x2_minus_x1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    \"\"\" DataSet class for representing and manipulating random datasets. \"\"\"\n",
    "    def __init__(self, N=10, dim=1, lower=0.0, upper=1.0):\n",
    "        \"\"\" Create a new data set assuming a uniform distribution between the \n",
    "            upper and lower bounds. \n",
    "        Args:\n",
    "        N (int): Number of points.\n",
    "        dim (int): Dimension of points.\n",
    "        lower (float): Lower bound.\n",
    "        upper (float): Upper bound.\n",
    "        \"\"\"\n",
    "        self.inputs = [RandomPoint(dim, lower, upper) for i in range(0,N)] # inputs (list(RandomPoint))\n",
    "        self.outputs = [TargetFunction(2, -1.0, 1.0, True).sign(input) for input in self.inputs] # outputs (list(int))\n",
    "        #self.data = list(zip(self.inputs, self.outputs)) # inputs (list(Tuple(RandomPoint, int)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \"\"\" Linear Regression class. \"\"\"\n",
    "    \n",
    "    def __init__(self, trainingSet, nonLinearTransform=False):\n",
    "        \"\"\" Create a new Linear Regression. \n",
    "        Args:\n",
    "        TrainingSet (DataSet): Training set.\n",
    "        nonLinearTransfom (bool): If false, use linear feature vector (1, x1, x2) \n",
    "                                  If true, use non-linear feature vector (1, x1, x2, x1*x2, x1**2, x2**2) \n",
    "        \"\"\"\n",
    "        self.trainingSet = trainingSet\n",
    "        self.nonLinearTransform = nonLinearTransform\n",
    "        self.xn = self.transformPoints(trainingSet.inputs)\n",
    "        \n",
    "    def run(self, targetFunction, fractNoise = 0.0):    \n",
    "        \"\"\"Run of Linear Regression Algorithm.\n",
    "        Args:\n",
    "        targetFunction (RandomLine): Random line\n",
    "        fractNoise (float): Fraction of noise to generate in the output (0.0 <= fracNoise <= 1.0)\n",
    "        Returns:\n",
    "        Tuple(g, yn)\n",
    "        \"\"\"\n",
    "        # calculate outputs and add noise\n",
    "        yn = np.array([targetFunction.sign(input) for input in self.trainingSet.inputs], copy=True) # outputs (list(int))\n",
    "        self.addNoise(yn, fractNoise)\n",
    "                \n",
    "        # calculate pseudo-inverse matrix and return g (weights)\n",
    "        X = self.xn\n",
    "        X_trans = np.transpose(X)\n",
    "        X_dagger = np.matmul(inv(np.matmul(X_trans, X)), X_trans)\n",
    "        return np.matmul(X_dagger, yn), yn\n",
    "    \n",
    "    def Ein(self, weights, yn):\n",
    "        \"\"\"Evaluate fraction of in-sample points which are misclassified\n",
    "        Args:\n",
    "        weights (np.ndarray): g function\n",
    "        yn (np.ndarray): f function (outputs)\n",
    "        Returns:\n",
    "        Fraction of in-sample points which are misclassified (0.0 <= float <= 1.0)\n",
    "        \"\"\"\n",
    "        ein = 0\n",
    "        for i in range(0, len(self.xn)):\n",
    "            if np.sign(np.matmul(np.transpose(weights), self.xn[i])) != yn[i]:\n",
    "                ein += 1\n",
    "        return float(ein / len(self.xn))\n",
    "    \n",
    "    def Eout(self, weights, targetFunction, fractNoise=0.0, npoints=1000):\n",
    "        \"\"\"Evaluate fraction of out-of-sample points which are misclassified\n",
    "        Args:\n",
    "        weights (np.ndarray): g function\n",
    "        targetFunction (TargetFunction): f function\n",
    "        fractNoise (float): Fraction of noise to generate in the output (0.0 <= fracNoise <= 1.0)\n",
    "        npoints (int): number of points to generate\n",
    "        Returns:\n",
    "        Fraction of in-sample points which are misclassified (0.0 <= float <= 1.0)\n",
    "        \"\"\"\n",
    "        # generate random points    \n",
    "        estPoints = [RandomPoint(2, -1.0, 1.0) for i in range(0, npoints)]\n",
    "        transPoints = self.transformPoints(estPoints)\n",
    "        \n",
    "        # compute outputs and add noise\n",
    "        yn = np.array([targetFunction.sign(estPoint) for estPoint in estPoints], copy=True)\n",
    "        self.addNoise(yn, fractNoise)\n",
    "        \n",
    "        # compute Eout\n",
    "        eout = 0\n",
    "        for i in range(0, len(transPoints)):\n",
    "            if np.sign(np.matmul(np.transpose(weights), transPoints[i])) != yn[i]:\n",
    "                eout += 1\n",
    "        return float(eout / len(transPoints))\n",
    "    \n",
    "    def Eout_closest(self, weights, hypotheses, targetFunction, fractNoise=0.0, npoints=1000):\n",
    "        \"\"\"Evaluate fraction of out-of-sample points which are misclassified\n",
    "        Args:\n",
    "        weights (np.ndarray): g function\n",
    "        hypotheses (List(np.ndarray)): potential g functions\n",
    "        targetFunction (TargetFunction): f function\n",
    "        fractNoise (float): Fraction of noise to generate in the output (0.0 <= fracNoise <= 1.0)\n",
    "        npoints (int): number of points to generate\n",
    "        Returns:\n",
    "        Tuple(int, float): Index of hypothesis in hypothesis that is besy match to weights and\n",
    "        the probability of the match\n",
    "        \"\"\"\n",
    "        # generate random points    \n",
    "        estPoints = [RandomPoint(2, -1.0, 1.0) for i in range(0, npoints)]\n",
    "        transPoints = self.transformPoints(estPoints)\n",
    "        \n",
    "        # compute outputs and add noise\n",
    "        #yn = np.array([targetFunction.sign(estPoint) for estPoint in estPoints], copy=True)\n",
    "        #self.addNoise(yn, fractNoise)\n",
    "        \n",
    "        # compute Eout\n",
    "        eouts = np.zeros(len(hypotheses))\n",
    "        for p in range(0, len(transPoints)):\n",
    "            for h in range(0, len(hypotheses)):\n",
    "                if np.sign(np.matmul(np.transpose(hypotheses[h]), transPoints[p])) \\\n",
    "                == np.sign(np.matmul(np.transpose(weights), transPoints[p])):\n",
    "                    eouts[h] += 1\n",
    "    \n",
    "        return np.argmax(eouts), float(np.max(eouts) / len(transPoints))\n",
    "    \n",
    "    # privates\n",
    "    def transformPoints(self, points):\n",
    "        if self.nonLinearTransform:\n",
    "            featureVectors = []\n",
    "            for pnt in points:\n",
    "                x1 = pnt.point[0]\n",
    "                x2 = pnt.point[1]\n",
    "                featureVector = [1.0, x1, x2, x1*x2, x1**2, x2**2]\n",
    "                featureVectors.append(featureVector)\n",
    "            return np.array(featureVectors)\n",
    "        else:\n",
    "            return np.array([np.insert(pnt.point, 0, 1.0) for pnt in points])\n",
    "        \n",
    "    def addNoise(self, outputs, fractNoise):\n",
    "        if fractNoise > 0.0:\n",
    "            idxs = [idx for (idx, value) in rd.sample(list(enumerate(outputs)), int(fractNoise * len(outputs)))]\n",
    "            for idx in idxs:\n",
    "                outputs[idx] = -outputs[idx] # flip the output in fracNoise of output      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runLinearRegression(trainingSet, fractNoise=0.0, line=True, nonLinearTransform=False, numRuns=1):\n",
    "    '''Run linear regression algorithm.\n",
    "    Args:\n",
    "    trainingSet (DataSet): Training set.\n",
    "    fracNoise (float): Fraction of noise to generate in the output (0.0 <= fracNoise <= 1.0)\n",
    "    line (bool): True if requesting to draw a line or false to generate the curve x1**2 + x2**2 - 0.6\n",
    "    numRuns (int): number of runs  \n",
    "    Returns:\n",
    "    meanEin (float): mean number of in-sample misclassifications\n",
    "    '''\n",
    "    mean_ein = 0.0\n",
    "    mean_eout = 0.0\n",
    "    for i in range(0, numRuns):\n",
    "        lr = LinearRegression(trainingSet, nonLinearTransform)\n",
    "        targetFunction = TargetFunction(2, -1.0, 1.0, line)\n",
    "        weights, yn = lr.run(targetFunction, fractNoise)\n",
    "        mean_ein += lr.Ein(weights, yn)\n",
    "        mean_eout += lr.Eout(weights, targetFunction, fractNoise, npoints=1000)\n",
    "    \n",
    "    mean_ein = mean_ein / numRuns\n",
    "    mean_eout = mean_eout / numRuns\n",
    "    return mean_ein, mean_eout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of mislassified in-sample points Ein =  0.03826000000000006\n",
      "Fraction of mislassified out-of-sample points Eout =  0.04862099999999999\n"
     ]
    }
   ],
   "source": [
    "mean_Ein, mean_Eout = runLinearRegression(DataSet(N=100, dim=2, lower=-1.0, upper=1.0), line=True, fractNoise=0.0, numRuns=1000)\n",
    "print(\"Fraction of mislassified in-sample points Ein = \", mean_Ein)\n",
    "print(\"Fraction of mislassified out-of-sample points Eout = \", mean_Eout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLA:\n",
    "    \"\"\" Perceptron Learning Algorithm (PLA) class. \"\"\"\n",
    "    \n",
    "    def __init__(self, initialWeights, trainingSet):\n",
    "        \"\"\" Create a new Perceptron Learning Algorithm (PLA). \n",
    "        Args:\n",
    "        dim (int): Dimension.\n",
    "        lower (float): Lower bound.\n",
    "        upper (float): Upper bound.\n",
    "        \"\"\"\n",
    "        self.initialWeights = initialWeights # initial weights\n",
    "        self.xn = np.array([np.insert(input.point, 0, 1.0) for input in trainingSet.inputs], copy=True) # training set inputs\n",
    "        self.trainingSet = trainingSet\n",
    "        #self.yn = np.array(trainingSet.outputs, copy=True) # training set outputs\n",
    "    \n",
    "    def run(self, targetFunction, maxIterations=100):    \n",
    "        \"\"\"Run of Perceptron Learning Algorithm (PLA).\n",
    "        Returns:\n",
    "        g\n",
    "        \"\"\"        \n",
    "        # calculate outputs\n",
    "        yn = np.array([targetFunction.sign(input) for input in self.trainingSet.inputs], copy=True) # outputs (list(int))\n",
    "        \n",
    "        # calculate target function (weights)\n",
    "        targetWeights = targetFunction.weights()\n",
    "        #print('Target weights ', targetWeights)\n",
    "        \n",
    "        # misclassified points\n",
    "        #misPointIdxs = self.misclassifiedPoints(self.initialWeights, yn)\n",
    "          \n",
    "        # PLA iterations\n",
    "        numIterations = 0\n",
    "        weights = np.copy(self.initialWeights) # initialize weights\n",