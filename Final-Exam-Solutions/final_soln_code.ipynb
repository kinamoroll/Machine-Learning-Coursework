{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import sys\n",
    "\n",
    "# Follow instructions here to get cvxopt working. --- painful!!! \n",
    "#https://stackoverflow.com/questions/46009925/how-to-install-cvxopt-on-on-windows-10-on-python-3-6\n",
    "from cvxopt import matrix, solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common code for questions 7-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training and testing data in pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    column_names = ['digit', 'intensity', 'symmetry']\n",
    "    sep = '\\s+'\n",
    "    features_train = pd.read_table('http://www.amlbook.com/data/zip/features.train', sep=sep, names=column_names)\n",
    "    features_test = pd.read_table('http://www.amlbook.com/data/zip/features.test', sep=sep, names=column_names)\n",
    "    return features_train, features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set output labels for classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_one_vs_all = dict(\n",
    "    {'zero_vs_all': 0,\n",
    "     'one_vs_all': 1,\n",
    "     'two_vs_all': 2,\n",
    "     'three_vs_all': 3,\n",
    "     'four_vs_all': 4,\n",
    "     'five_vs_all': 5,\n",
    "     'six_vs_all': 6,\n",
    "     'seven_vs_all': 7,\n",
    "     'eight_vs_all': 8,\n",
    "     'nine_vs_all': 9\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_one_vs_five = {'one_vs_five': [1,5]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create one-versus-all and one-versus-five dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_vs_all_dataframe(df, classifiers):\n",
    "    # add binary labels to dataframe\n",
    "    one_vs_all = pd.DataFrame(df, copy=True)\n",
    "    for class_label, digit in classifiers.items():\n",
    "        labels = one_vs_all.loc[one_vs_all['digit'] == digit, 'digit']\n",
    "        labels.loc[:] = 1.0\n",
    "        one_vs_all[class_label] = labels\n",
    "        \n",
    "    one_vs_all.fillna(-1.0, inplace=True)\n",
    "    return one_vs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_one_vs_all = create_one_vs_all_dataframe(features_train, classifiers_one_vs_all)\n",
    "features_test_one_vs_all = create_one_vs_all_dataframe(features_test, classifiers_one_vs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_vs_one_dataframe(df, classifiers):\n",
    "    # add binary labels to dataframe  \n",
    "    for class_label in classifiers.keys():\n",
    "        digits = classifiers[class_label]\n",
    "        one_vs_one = pd.DataFrame(df.loc[df['digit'].isin(digits),:], copy=True)\n",
    "        for digit in digits:\n",
    "            labels = one_vs_one.loc[one_vs_one['digit'] == digit, 'digit']\n",
    "            labels.loc[:] = 1.0\n",
    "            one_vs_one[class_label] = labels\n",
    "            break\n",
    "        \n",
    "    one_vs_one.fillna(-1.0, inplace=True)\n",
    "    return one_vs_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_one_vs_five = create_one_vs_one_dataframe(features_train, classifiers_one_vs_five)\n",
    "features_test_one_vs_five = create_one_vs_one_dataframe(features_test, classifiers_one_vs_five)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dataset (inputs / outputs) for a specific classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(df, class_label):\n",
    "    inputs = np.array(df.loc[:, ['intensity', 'symmetry']])\n",
    "    outputs = np.array(df.loc[:, class_label])\n",
    "    data = np.column_stack((inputs, outputs))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of regularized least-squares linear regression for classiﬁcation that minimizes:\n",
    "\n",
    "$$\\frac{1}{N}\\sum_{n=1}^{N}(\\textbf{w}^{T}\\textbf{z}_{n}-y_{n})^{2}+\\frac{\\lambda}{N}\\textbf{w}^{T}\\textbf{w}$$\n",
    "\n",
    "where $\\textbf{w}$ includes $w_{0}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \"\"\" Class that performs regularized least-squares linear regression for classification. \"\"\"\n",
    "    \n",
    "    def __init__(self, transform=False):\n",
    "        \"\"\" Create a Linear Regression Algorithm. \n",
    "        Args:\n",
    "        transform (bool): If True, apply a feature transform z = (1, x1, x2, x1.x2, x1^2, x2^2) to the inputs (x1, x2)\n",
    "                          Otherwise, use inputs as they are so z = (1, x1, x2)\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "    \n",
    "    def fit(self, inputs, outputs, llambda=1.0):    \n",
    "        \"\"\"Fit the training data using the regularized least-squares linear regression learning algorithm\n",
    "        Args:\n",
    "        inputs (np.ndarray): Inputs\n",
    "        outputs (np.ndarray): Outputs\n",
    "        llambda (float): Regularization parameter\n",
    "        Returns:\n",
    "        np.ndarray: Weights\n",
    "        \"\"\"      \n",
    "        # get inputs and outputs\n",
    "        Z = self.transform_inputs(inputs)\n",
    "        y = outputs\n",
    "        \n",
    "        # linear regression solution with regularization\n",
    "        Z_trans = np.transpose(Z)\n",
    "        normZ = np.matmul(Z_trans, Z)  \n",
    "        I = np.identity(np.size(normZ, axis=0))\n",
    "        weights = np.matmul(np.linalg.inv(np.add(normZ, llambda * I)), np.matmul(Z_trans, y))\n",
    "        return weights\n",
    "    \n",
    "    def binary_error(self, weights, inputs, outputs):    \n",
    "        \"\"\"Compute binary classification error of sample\n",
    "        Args:\n",
    "        weights (np.ndarray): Weights of hypothesis\n",
    "        inputs (np.ndarray): Inputs\n",
    "        outputs (np.ndarray): Outputs\n",
    "        Returns:\n",
    "        float: Binary classification error (fraction of misclassified points in the sample)\n",
    "        \"\"\"\n",
    "        Z = self.transform_inputs(inputs)\n",
    "        y = outputs\n",
    "        \n",
    "        g = [np.sign(np.dot(weights.T, z)) for z in Z]\n",
    "        return sum(g != y) / len(y)        \n",
    "         \n",
    "    # privates\n",
    "    def transform_inputs(self, inputs):\n",
    "        ones = np.ones(len(inputs)).reshape(len(inputs), 1)\n",
    "        x1 = inputs[:, 0].reshape(len(inputs), 1)\n",
    "        x2 = inputs[:, 1].reshape(len(inputs), 1)\n",
    "        \n",
    "        if self.transform:\n",
    "            return np.concatenate((ones, x1, x2, x1*x2, x1**2, x2**2), axis=1)\n",
    "        else:\n",
    "            return np.concatenate((ones, x1, x2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute in-sample and out-of-sample errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_out_sample_errors(classifiers, features_train, features_test=pd.DataFrame(), llambda=1.0, transform=False):\n",
    "    results = []\n",
    "    \n",
    "    for class_label in classifiers.keys():\n",
    "            # get training data\n",
    "            dataset_train = get_dataset(features_train, class_label)\n",
    "            inputs_train = dataset_train[:, 0:2]\n",
    "            outputs_train = dataset_train[:, 2]\n",
    "            \n",
    "            # fit the model\n",
    "            lr = LinearRegression(transform)\n",
    "            weights = lr.fit(inputs_train, outputs_train, llambda)\n",
    "            \n",
    "            # compute in-sample error\n",
    "            error_in_sample = lr.binary_error(weights, inputs_train, outputs_train)\n",
    "            \n",
    "            # get testing data\n",
    "            error_out_sample = None\n",
    "            if not features_test.empty:\n",
    "                dataset_test = get_dataset(features_test, class_label)\n",
    "                inputs_test = dataset_test[:, 0:2]\n",
    "                outputs_test = dataset_test[:, 2]\n",
    "                \n",
    "                # compute out-of-sample error\n",
    "                error_out_sample =  lr.binary_error(weights, inputs_test, outputs_test)\n",
    "            \n",
    "            # add to results\n",
    "            result = {'classifier': class_label,\n",
    "                      'transform': transform,\n",
    "                      'lambda': llambda,\n",
    "                      'ein': error_in_sample,\n",
    "                      'eout': error_out_sample}\n",
    "            results.append(result)\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_binary_errors(results, print_classifiers=None, print_errors='both'):   \n",
    "    if print_errors not in ['ein', 'eout', 'both']:\n",
    "        raise ValueError('\"print_errors\" must either \"ein\", \"eout\" or \"both\"')\n",
    "    \n",
    "    for result in results:\n",
    "        if isinstance(print_classifiers, list) and result['classifier'] not in print_classifiers:\n",
    "            continue\n",
    "        \n",
    "        if print_errors == 'ein':\n",
    "            print('For transform = {0} and λ = {1}, the \"{2}\" classifier in-sample error Ein = {3}'\n",
    "                  .format(result['transform'], result['lambda'], result['classifier'], round(result['ein'], 3)))\n",
    "        elif print_errors == 'eout':\n",
    "            print('For transform = {0} and λ = {1}, the \"{2}\" classifier in-sample error Eout = {3}'\n",
    "                  .format(result['transform'], result['lambda'], result['classifier'], round(result['eout'], 3)))\n",
    "        elif print_errors == 'both':\n",
    "            print('For transform = {0} and λ = {1}, the \"{2}\" classifier in-sample error Ein = {3} '\n",
    "                  'and the out-of-sample-error Eout = {4}'\n",
    "                  .format(result['transform'], result['lambda'], result['classifier'], \n",
    "                          round(result['ein'], 3), round(result['eout'], 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Compute in-sample error for 5-versus-all through to 9-versus-all classifier for $\\lambda$ = 1 without a feature transform $z = x = (1, x_{1}, x_{2})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = in_out_sample_errors(classifiers_one_vs_all, features_train_one_vs_all, llambda=1.0, transform=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For transform = False and λ = 1.0, the \"five_vs_all\" classifier in-sample error Ein = 0.076\n",
      "For transform = False and λ = 1.0, the \"six_vs_all\" classifier in-sample error Ein = 0.091\n",
      "For transform = False and λ = 1.0, the \"seven_vs_all\" classifier in-sample error Ein = 0.088\n",
      "For transform = False and λ = 1.0, the \"eight_vs_all\" classifier in-sample error Ein = 0.074\n",
      "For transform = False and λ = 1.0, the \"nine_vs_all\" classifier in-sample error Ein = 0.088\n"
     ]
    }
   ],
   "source": [
    "print_binary_errors(results, print_classifiers=['five_vs_all', \n",
    "                                                'six_vs_all', \n",
    "                                                'seven_vs_all', \n",
    "                                                'eight_vs_all', \n",
    "                                                'nine_vs_all'],\n",
    "                    print_errors='ein')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Compute out-of-sample error for 0-versus-all through to 4-versus-all classifier for $\\lambda$ = 1 with a feature transform $z = (1, x_{1}, x_{2}, x_{1}x_{2}, x_{1}^2, x_{2}^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = in_out_sample_errors(classifiers_one_vs_all, features_train_one_vs_all, features_test_one_vs_all, llambda=1.0, \n",
    "                               transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For transform = True and λ = 1.0, the \"zero_vs_all\" classifier in-sample error Eout = 0.107\n",
      "For transform = True and λ = 1.0, the \"one_vs_all\" classifier in-sample error Eout = 0.022\n",
      "For transform = True and λ = 1.0, the \"two_vs_all\" classifier in-sample error Eout = 0.099\n",
      "For transform = True and λ = 1.0, the \"three_vs_all\" classifier in-sample error Eout = 0.083\n",
      "For transform = True and λ = 1.0, the \"four_vs_all\" classifier in-sample error Eout = 0.1\n"
     ]
    }
   ],
   "source": [
    "print_binary_errors(results, print_classifiers=['zero_vs_all', \n",
    "                                                'one_vs_all', \n",
    "                                                'two_vs_all', \n",
    "                                                'three_vs_all', \n",
    "                                                'four_vs_all'],\n",
    "                    print_errors='eout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Compare the in-sample and out-of-sample errors for 0-versus-all through to 9-versus-all classifier for $\\lambda$ = 1 with and without the feature transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = in_out_sample_errors(classifiers_one_vs_all, features_train_one_vs_all, features_test_one_vs_all, llambda=1.0, \n",
    "                               transform=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For transform = False and λ = 1.0, the \"zero_vs_all\" classifier in-sample error Ein = 0.109 and the out-of-sample-error Eout = 0.115\n",
      "For transform = False and λ = 1.0, the \"one_vs_all\" classifier in-sample error Ein = 0.015 and the out-of-sample-error Eout = 0.022\n",
      "For transform = False and λ = 1.0, the \"two_vs_all\" classifier in-sample error Ein = 0.1 and the out-of-sample-error Eout = 0.099\n",
      "For transform = False and λ = 1.0, the \"three_vs_all\" classifier in-sample error Ein = 0.09 and the out-of-sample-error Eout = 0.083\n",
      "For transform = False and λ = 1.0, the \"four_vs_all\" classifier in-sample error Ein = 0.089 and the out-of-sample-error Eout = 0.1\n",
      "For transform = False and λ = 1.0, the \"five_vs_all\" classifier in-sample error Ein = 0.076 and the out-of-sample-error Eout = 0.08\n",
      "For transform = False and λ = 1.0, the \"six_vs_all\" classifier in-sample error Ein = 0.091 and the out-of-sample-error Eout = 0.085\n",
      "For transform = False and λ = 1.0, the \"seven_vs_all\" classifier in-sample error Ein = 0.088 and the out-of-sample-error Eout = 0.073\n",
      "For transform = False and λ = 1.0, the \"eight_vs_all\" classifier in-sample error Ein = 0.074 and the out-of-sample-error Eout = 0.083\n",
      "For transform = False and λ = 1.0, the \"nine_vs_all\" classifier in-sample error Ein = 0.088 and the out-of-sample-error Eout = 0.088\n"
     ]
    }
   ],
   "source": [
    "print_binary_errors(results, print_errors='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = in_out_sample_errors(classifiers_one_vs_all, features_train_one_vs_all, features_test_one_vs_all, llambda=1.0, \n",
    "                               transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For transform = True and λ = 1.0, the \"zero_vs_all\" classifier in-sample error Ein = 0.102 and the out-of-sample-error Eout = 0.107\n",
      "For transform = True and λ = 1.0, the \"one_vs_all\" classifier in-sample error Ein = 0.012 and the out-of-sample-error Eout = 0.022\n",
      "For transform = True and λ = 1.0, the \"two_vs_all\" classifier in-sample error Ein = 0.1 and the out-of-sample-error Eout = 0.099\n",
      "For transform = True and λ = 1.0, the \"three_vs_all\" classifier in-sample error Ein = 0.09 and the out-of-sample-error Eout = 0.083\n",
      "For transform = True and λ = 1.0, the \"four_vs_all\" classifier in-sample error Ein = 0.089 and the out-of-sample-error Eout = 0.1\n",
      "For transform = True and λ = 1.0, the \"five_vs_all\" classifier in-sample error Ein = 0.076 and the out-of-sample-error Eout = 0.079\n",
      "For transform = True and λ = 1.0, the \"six_vs_all\" classifier in-sample error Ein = 0.091 and the out-of-sample-error Eout = 0.085\n",
      "For transform = True and λ = 1.0, the \"seven_vs_all\" classifier in-sample error Ein = 0.088 and the out-of-sample-error Eout = 0.073\n",
      "For transform = True and λ = 1.0, the \"eight_vs_all\" classifier in-sample error Ein = 0.074 and the out-of-sample-error Eout = 0.083\n",
      "For transform = True and λ = 1.0, the \"nine_vs_all\" classifier in-sample error Ein = 0.088 and the out-of-sample-error Eout = 0.088\n"
     ]
    }
   ],
   "source": [
    "print_binary_errors(results, print_errors='both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Compare the in-sample and out-of-sample errors for 0-versus-all through to 9-versus-all classifier for λ = 1.0 and λ = 0.01 with feature transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = in_out_sample_errors(classifiers_one_vs_five, features_train_one_vs_five, features_test_one_vs_five, llambda=1.0, \n",
    "                               transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For transform = True and λ = 1.0, the \"one_vs_five\" classifier in-sample error Ein = 0.005 and the out-of-sample-error Eout = 0.026\n"
     ]
    }
   ],
   "source": [
    "print_binary_errors(results, print_errors='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = in_out_sample_errors(classifiers_one_vs_five, features_train_one_vs_five, features_test_one_vs_five, llambda=0.01, \n",
    "                               transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For transform = True and λ = 0.01, the \"one_vs_five\" classifier in-sample error Ein = 0.004 and the out-of-sample-error Eout = 0.028\n"
     ]
    }
   ],
   "source": [
    "print_binary_errors(results, print_errors='both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common code for questions 11-12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_set():\n",
    "    return np.array([1., 0., -1.,\n",
    "                     0., 1., -1.,\n",
    "                     0., -1., -1.,\n",
    "                     -1., 0., 1.,\n",
    "                     0., 2., 1.,\n",
    "                     0., -2., 1.,\n",
    "                     -2., 0., 1.]).reshape(7, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_training_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(features, label, features_names=['$x_{1}$', '$x_{2}$'], plot_hyperplanes=False):\n",
    "    plt.scatter(features[:, 0], features[:, 1], c=label, cmap='rainbow');\n",
    "    plt.xlabel(features_names[0]);\n",
    "    plt.ylabel(features_names[1]);\n",
    "    \n",
    "    if plot_hyperplanes:\n",
    "        eps = 1e-12 # to prevent divide by zero\n",
    "        xfit = np.linspace(-3.5, 3.5)\n",
    "        \n",
    "        for w1, w2, b in [(-1., 1., -0.5), (1., -1., -0.5), (1., 0., -0.5), (0., 1., -0.5)]:\n",
    "            slope = -w1 / (w2+eps)\n",
    "            intercept = -b / (w2+eps)\n",
    "            yfit =  slope * xfit + intercept\n",
    "            plt.plot(xfit, yfit, label=\"w1 = {0}, w2 = {1}, b = {2}\".format(str(w1), str(w2), str(b)))\n",
    "            plt.legend(loc='upper left')\n",
    "        \n",
    "        plt.xlim(-3.5, 3.5);\n",
    "        plt.ylim(-3.5, 5.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the data is not linearly separable in the $\\mathcal{X}$ space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ca23489ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data(train_data[:, 0:2], train_data[:, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform this training set into another two-dimensional space $\\mathcal{Z}$\n",
    "\n",
    "$$z_{1}=x_{2}^{2}-2x_{1}-1\\qquad z_{2}=x_{1}^{2}-2x_{2}+1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_inputs(inputs):\n",
    "    x1 = inputs[:, 0].reshape(len(inputs), 1)\n",
    "    x2 = inputs[:, 1].reshape(len(inputs), 1)\n",
    "    return np.concatenate((x2**2 - 2*x1 - 1, x1**2 - 2*x2 + 1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = transform_inputs(train_data[:, 0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the data is now linearly separable in the $\\mathcal{Z}$ space (the last two points map on to the same point (3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ca253bea90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data(train_inputs[:, 0:2], train_data[:, 2], features_names=['$z_{1}$', '$z_{2}$'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of hard-margin Support Vector Machines (SVM) classification learning algorithm using the kernel:\n",
    "\n",
    "$$K(x,x')=(1+\\textbf{x}_{T}\\textbf{x}')^{2}$$\n",
    "\n",
    "which corresponds to a second-order polynomial transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    \"\"\" Class that performs hard-margin Support Vector Machines (SVM) classification using polynomial kernel of degree 2. \"\"\"\n",
    "    def __init__(self, kernel='poly', Q=2, gamma=1.0):\n",
    "        \"\"\" Create a Support Vector Machine Algorithm (SVM). \n",
    "        Args:\n",
    "        kernel (string): Kernel to use, \"poly\" (polynomial) or \"rbf\" (radial basis function)\n",
    "        Q (int): Degree of the polynomial kernel (Q >= 0)\n",
    "        gamma (float): Constant in the RBF kernel\n",
    "        \"\"\"\n",
    "        if kernel not in ['poly','rbf']:\n",
    "            raise ValueError('Kernel must be \"poly\" or \"rbf\".')\n",
    "        \n",
    "        self.kernel = kernel\n",
    "        self.Q = Q\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def fit(self, inputs, outputs):\n",
    "        \"\"\"Fit the training data using the hard-margin Support Vector Machines (SVM) learning algorithm.\n",
    "        Args:\n",
    "        inputs (np.ndarray): Input points.\n",
    "        outputs (np.ndarray): Targets.\n",
    "        Returns:\n",
    "        Tuple(np.ndarray, np.ndarray, np.ndarray, float): alphas, support vectors, support vector outputs, b\n",
    "        \"\"\" \n",
    "        xn = inputs\n",
    "        yn = outputs\n",
    "        N = len(xn)\n",
    "        \n",
    "        mat = []\n",
    "        for row_idx in range(0, N):\n",
    "            for col_idx in range(0, N):\n",
    "                if self.kernel == 'poly':\n",
    "                    kernel = self.kernel_poly(xn[row_idx], xn[col_idx])\n",
    "                elif self.kernel == 'rbf':\n",
    "                    kernel = self.kernel_rbf(xn[row_idx], xn[col_idx])\n",
    "                val = yn[row_idx] * yn[col_idx] * kernel\n",
    "                mat.append(val)\n",
    "        mat = np.array(mat).reshape((N, N))\n",
    "        \n",
    "        # form matrices for quadratic programming solver\n",
    "        dim = len(xn[0])\n",
    "        P = matrix(mat, tc='d')\n",
    "        q = matrix(-np.ones(N), tc='d')\n",
    "        b = matrix(0.0, tc='d')\n",
    "        A = matrix(yn, tc='d')\n",
    "        A = A.trans()\n",
    "        G = matrix(-np.identity(N), tc='d')\n",
    "        h = matrix(np.zeros(N), tc='d')\n",
    "        \n",
    "        #print('P = ', P)\n",
    "        #print('q = ', q)\n",
    "        #print('G = ', G)\n",
    "        #print('h = ', h)\n",
    "        #print('A = ', A)\n",
    "        #print('b = ', b)\n",
    "                \n",
    "        # call qp solver to compute weights\n",
    "        solvers.options['show_progress'] = False # supress solver output\n",
    "        \n",
    "        sol = solvers.qp(P, q, G, h, A, b)\n",
    "        alpha = np.array(list(sol['x']))\n",
    "        #print('alpha = ', sol['x'])\n",
    "        \n",
    "        weights = np.zeros(dim)\n",
    "        sv = []\n",
    "        sv_alphas = []\n",
    "        sv_outputs = []\n",
    "        for n in range(0, N):\n",
    "            if alpha[n] > 1e-5: # => xn[n] is support vector\n",
    "                sv.append(xn[n])\n",
    "                sv_alphas.append(alpha[n])\n",
    "                sv_outputs.append(yn[n])\n",
    "                    \n",
    "        # compute number of support vectors \n",
    "        num_sv = len(sv)\n",
    "        if (num_sv == 0):\n",
    "            raise Exception('There are no support vectors.')\n",
    "        \n",
    "        bs = []\n",
    "        for m in range(0, num_sv):\n",
    "            b = sv_outputs[m]\n",
    "            for n in range(0, num_sv):\n",
    "                if self.kernel == 'poly':\n",
    "                    kernel = self.kernel_poly(sv[n], sv[m])\n",
    "                elif self.kernel == 'rbf':\n",
    "                    kernel = self.kernel_rbf(sv[n], sv[m])\n",
    "                b -= sv_alphas[n] * sv_outputs[n] * kernel\n",
    "            bs.append(b)\n",
    "                \n",
    "        bs_round = np.round(bs, 1)\n",
    "        #print('bs sv = ', bs)\n",
    "        \n",
    "        #print('bs = ', bs)\n",
    "        #print('bs_round = ', bs_round)\n",
    "        #print('np.unique(bs_round) = ', np.unique(bs_round))\n",
    "        \n",
    "        #if (len(np.unique(bs_round)) != 1):\n",
    "        #    raise Exception('All support vectors must produce the same value of b.')\n",
    "            \n",
    "        weights = np.insert(weights, 0, b)\n",
    "        #print('weights = ', weights)\n",
    "\n",
    "        return np.array(sv_alphas), np.array(sv), np.array(sv_outputs), b\n",
    "    \n",
    "    def binary_error(self, sv_alphas, sv, sv_outputs, b, inputs, outputs):\n",
    "        \"\"\" Evaluate binary classification error. \n",
    "        Args:\n",
    "        sv_alphas (np.ndarray): Support vector Lagrange multipliers.\n",
    "        sv (np.ndarray): Support vectors.\n",
    "        sv_outputs (np.ndarray): Support vector outputs.\n",
    "        b (float): Constant.\n",
    "        inputs (np.ndarray): Inputs.\n",
    "        outputs (np.ndarray): Outputs.\n",
    "        Returns (float): Binary classification error percentage\n",
    "        \"\"\"\n",
    "        x = inputs\n",
    "        y = outputs\n",
    "        num_sv = len(sv)\n",
    "        \n",
    "        gs = []\n",
    "        for xm in x:\n",
    "            signal = 0.0\n",
    "            for n in range(0, num_sv):\n",
    "                if self.kernel == 'poly':\n",
    "                    kernel = self.kernel_poly(sv[n], xm)\n",
    "                elif self.kernel == 'rbf':\n",
    "                    kernel = self.kernel_rbf(sv[n], xm)\n",
    "                signal += sv_alphas[n] * sv_outputs[n] * kernel\n",
    "            signal += b\n",
    "            gs.append(signal)\n",
    "                \n",
    "        g = np.array(np.sign(gs))\n",
    "        return 100. * np.sum(y != g) / len(y)   \n",
    "    \n",
    "    # privates\n",
    "    def kernel_poly(self, xn, xm):\n",
    "        return (1.0 + np.dot(xn.T, xm))**self.Q\n",
    "    \n",
    "    def kernel_rbf(self, xn, xm):\n",
    "        return np.exp(-self.gamma * (np.linalg.norm(xn - xm)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the hyperplane is described by the equation, $\\textbf{w}^{T}\\textbf{z} + b = 0$, we can now plot the hyperplanes given by the values of $w_{1}$, $w_{2}$, b: \n",
    "- [-1, 1, 0.5]\n",
    "- [1, -1, -0.5]\n",
    "- [1, 0, -0.5]\n",
    "- [0, 1, -0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEHCAYAAABGNUbLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzs3Xd8W/W9//GXlveM95accbL3trOd6SROyiil7W2BNi00HYwWWsrlltILtNBCKW2hQKHQ3sKvQALEJHEWiR1n73UyLO/tyNvWPL8/nISExHbiWD6S830+HjweWNI55y1Ffuv4SPocjaIoCIIgCLcWrdoBBEEQhL4nyl8QBOEWJMpfEAThFiTKXxAE4RYkyl8QBOEWJMpfEAThFqRXO8D1qqlpcttnUsPDA7BYWt21ercT+dXlzvwFjz4MQOpzL7hl/SAefzW5O3tUVLCms+vEnj+g1+vUjnBTRH51ifzq8ub8amYX5S8IgnALEuUvCIJwCxLlLwiCcAsS5S8IgnALEuUvCIJwCxLlLwiCoBaXS7VNi/IXBEHoSw4HocsXEpEcDQYDAwYmEvjjH/R5DNW+5CVJ0kGg4cKPZlmW71EriyAIQl8Jm5uO/tQJLn77StfUiP//vYPG5aL55b/0WQ5Vyl+SJD8AWZZnq7H9vmKxWLj//nt5++1/4+vr2yvr/OMfXyA5OYUVK26/4nKXy8ULLzzL2bNnMBgMPPbYEyQmJvVoG++99082bdoIwLRpadx776oeraer+19aWsJvfvM/aDQahg8fygMPPIRWe+0/RFevXsVPf/oLUlKMPcrxZVZrO0899QQWi4WAgAAef/xXhIeHX3GbRx99kMbGBnQ6Pb6+frzwwh97ZdvCrU176iR6+SRf/tqtBvBZtxb6e/kDY4AASZI2XsjwC1mWd93MCt/fcpa9p6p7tKxOp8HpvHp6xKSh0dw5d1CP1rl7dz5//evLnD9/vkfLf5nFYuHpp5+kpKSIu+/+5lXX79ixDZvNxquv/p1jx47ypz/9gWef/f0Nb6esrJSNG9fz2mtvodFo+MEPvsPMmXMYNGjwDa2nu/v/8su/57vfvZ/x4yfy8su/Y8eOz5k1a84N5+2Jjz76D6mpg7jvvu+xadMG3n77DX7yk0euuE1ZWSnvvPM+Gk2n344XhBvm994/0XRy9kRtSwu0tkJAQJ9kUav8W4HngdeBwcBnkiRJsiw7OlsgPDygy69C+wf4oNP1/Bf1Wsv6B/gQFRV8zduvXLmS119/nZCQEKZMmcK7777L8OHDWblyJe+99x7h4YG8884/uO2224iKCr5qz/fxxx+nuLj40s+hoaH86U9/6jRfe3s9Dz/8E7Zv305QkN9Vuc6cOcH8+XOJigpmzpzp/Pd/P9rj7G+99SYDBoRduLVCbGz4Feu6nuzd3f8zZ2QWLJiNRqNh5syZ5OXlcfvty6+Z18dHzzvvvI7FYsHHx4ff/va3DBgw4NL17777Lhs2bLhimeeee474+Phrrk+Wj/Od73yHqKhgli5dyLvv/v2K+1dbW0tLSzNPPPFTGhsbWbVqFXPmdP3C1NljfbOKdFq3rv8id6/f3bwm/7zZ8Mq1/4rUGAxEJUVBJ38B9za1yv80cFaWZQU4LUlSHRAHlHS2QHfDj5ZNTWbZ1OQehYmKCqampuma13V2+bRpM8jOziE6OobY2Hg2btxCc7OduLgEGhqsDBkyGocDnE4XNTVN+Prarlj+Jz957Lq3BeDnF0Z8fBgtLTn4+bVfcduoqGBqay04nbrLLtdQUWFBr7/6n7i77GCgurqRV155CZNpEEFBkVds73qyd3f/nU4XtbXNAAQGBlJba+n0/ttsDqZOnUFGxkI+/PD/8eKLL/PDHz506fqFC7NYuDCr20wXnT/fgN2upaamCZfLRUND4xW3raqycOedX+eOO+6iqamR+++/j4SEVMLDB1xzfV09f26W09nxaRB3rR/cm78veFX+9AwGRESgq6u76irbiJE01LX06ua6elFUq/zvBUYBD0iSFA+EABUqZemRWbPm8PbbbxITE8uqVQ/wn//8G5dLYdasede1/LPP/prS0i9e60JCQvnf//3dpZ+3bt3EBx+8D8Dq1Q8ydOiwLtcXGBhIa+sXL5CKolyz+K8nu9Vq5ZlnniIgIICHH7666LvLfj0uP77f0tJCUFBQl7cfO3Y8AKNGjSY/P/eK6z744D22bt18xWW//OVTxMbGAh3vLzz77K8BWLRoyYXHquOXrLW19aptR0REsmLFbej1esLDBzB4sERxcVGn5S8IN6L+/bWE3ZGF9nwdGkABnKkDaVi7vk9zqFX+bwBvSZKUS8d9v7erQz6eKDV1EBUV5Zw/X8f3v7+ad975O7m5n/OHP7xyXcs/9tgTXV4/Z04Gc+ZkXHeeUaPGkJe3g3nz5nPs2FFSUzt/r6Kr7Iqi8POfP8z48RP5xje+3aPs12PwYIkDB/YxfvxEtm/fzpgx47q8/YkTx5k5czaHDx/EZBp4xXW33fZVbrvtq50um5iYxJ/+9Nqln5uamsnPz2P48JHs2pV31bb37t3Nhx++z+9+9xKtra2YzedISTH14F4KwtVco0Zz/pQZwwfvE3ZoL5blt+OcNKXPc6hS/rIs24C71dh2bxo7djwVFeVotVrGjh1PYWEBAX30Zs1Fv/71f/PYYz9l5sw57N27m+9//14UReEXv3gSgHfeeYvBg4cwder068r++edbOXToADabjV27dgLw/e+vZuTI0Ted1Wwu4IMP3ueRRx5j9eqf8Nvf/oZXX30FSRrM7Nkdf3WsXr3qiqK+aMeObbz//r8IDAzk8cd/dVM5Vq68naeffpL7778Pg8HAk08+DcCf//wSs2fPY9q0NPbs2cWqVd9Gq9WyatUPCAsL62atgnBj7LfdCd+/D6dKh6w0SifvPHsad57MxauOGV5DV/lzcz/H3z+ACRMm9XGq63d5/hdffP6qT954Onc+f/riZC79+fnv6dydvauTuXjNmbyEnhk0SLp07NsbfO1r31A7giDcEsR4h37Om4ofICbGu/IKgrcS5S8IgnALEuUvCIJwCxLlLwiCcAsS5S8IgnALEuXvRhaLhbvuWonVanXLOkpLS7j//vu4++67ef75Z3D18MQQzc3N/OxnD7J69Sq+9717OHbsSI/zXu56sj/wwHd48sknu8y+evUqiooKeyUTdEz1fPzxn/LAA9/hkUd+hMViueo2jz76IPfffy+rV6/i4Yd/1GvbFgRP0W8+6vnh2U85WH20R8vqtBqcrqu/RjAuehRfGbS0R+vsjame1zsZc+HCOfzsZz/v8WTM9977JxMnTuLOO++muLiQ//mfx3nzzX/2OPeNZBdTPQVBHWLPv4fuvffrWCzncTgcLFgwi9OnT1263GazodVqePHFPxMSEnLN5Z999tesXr3q0n+/+MVPr7pNd+uQ5VOMGzcBgKlTp7Nv355r3u7MGZmf/ewnAOTkrOdb3/oaAIcPH+K5537DnXfeTVbWVwBwOJz4+Fw9e//yrKtXr2Lt2g+7fHxuJPvMmTM7zX7R66//lR/96Ps8/PDVe+offPDeVfkqKys7XdeRI4eZMqXjG89Tp6Zdte3z5+toamq6sPd/H3l5O7rMJgjeqN/s+X9l0NIe76X35Ft2M2bMZvfufKKjY4iLi2fv3t0YDD4kJSXj4+PDpElTu1z+eubjdLcORVEu7ZkGBATS0tJ8zdsNHixRWVmB1Wpl9+58NBoN58/XkZfXsbcdHNwx+a+urpZf//oJfvSjh69Y/suzca7HjWQPDOw8+0WzZs25NNXz3Xf/fsVUz+5m+3zZ5YPkAgICrtq23W7nrru+ccVUz+HDR4jBbkK/0m/Kv6+5e6rn9bh8MmZra9eTMSdPnsbBg/uprq5iwYJF7Nu3h0OHDrJqVce5Q8+dO8uTT/6CH/zgx5f2yC+6fCrmRfPnL7r018Ll9ycsLJynn37uhrKLqZ6C0PdE+feQu6d6Xo+LkzEXLpzDrl07GT9+Yqe3nTlzNq+99mcGD5aYPHkav/vd/5KUlIRer8dsLuCJJx7lV796hsGDh1y17PXs+d/o/RFTPQVBXeKY/00YO3Y8YWHhlyZjhoeHu32qp9lcwPPPPwvA6tU/4c03X+OrX/0qdrv9ismYXzZq1BhKSoqYPHkKgwYNprKygpkz5wLw6qt/wmaz8dJLz7N69Soee+yhq5Z3V/bvfe+ebrNDx1TP1atXsXfv7k5HTV+vlStvx2wu4P777+Pjjz/innu+C3RM9Txx4hjTpqWRmJjMqlXf5qGHVoupnkK/JKZ64t1TAeHq/N42GVNM9eycmOrZPW/Or+ZUT7Hn3w9582RMb84uCN5E1WP+kiRFA/uB+bIsn1IzS3/izZMxvTm7IHgT1fb8JUkyAK8CbWplEARBuFWpedjneeCvQLmKGQRBEPoVRVE4VlDHb/6xr8vbqXLYR5KkbwM1sixvkCTp59ezTHh4AHq9zm2ZoqKC3bbuviDyq8td+Yt0Wreu/yLx+Kunt7IrisLhMzX8a4PMycLux8qodcz/XkCRJCkDGAv8Q5Kk5bIsd/qdfIul1W1hvPnTAiDyq82d+Z3OjoF3bv5EiHj8VdJb2U8WWVizo4AzpQ0AjB0USVZ6199NUaX8ZVmeefH/JUnaBny/q+L3VhaLhfvvv5e33/43vr6+3S9wg+soLS3hN7/5H3x89CQlGXnooUev+Obs9Wpubuapp56gtbUFu93OD3/4ICNHjr6hdVit7Tz11BNYLBYCAgJ4/PFfER4efsVt3nzzNfLzc9Hp9PzoRw8xfPjIa67rwIF9rF37Ab/61TM3fF86k5u7nbfeeh2dTkdm5nKWL195xfWyfIpHH32QxMQkoOO7APPmLei17QuCO8jFFtbsMCOX1AMwZmAEWTNMGGOvPVPrcv3mG741/+/fNO3b26Nli3TaS3tYlwueOImoO+7q0Tpvtame3U3KlOVTHDp0gNdee5uqqip++cuf8frr/7jhrD3hcDh4+eXf87e//QN/f3/uv/8+0tJmEBEReek2p0+f4qtf/br4qKngFU6X1LNmRwGnijtKf/TACLLSTZjiui/9i1Qvf1mWZ6udoSfuvffrvPDCywQHh7BkyTz+9KdXGTJkKPfe+3X++te/X5pqed9937zm8tcz26e7dXx5queePbuvWf5nzsj87W9/4be/fZGcnPW8++7bvP32/3H48CHWr1/HAw/8CB8fA9D5VM/uZvscOXKYu+/+rwtZ0njrrTeuuP2RI4eYNGkqGo2G2NhYnE4HFovlqr8OLiopKeGhh1bT0NDAypW3sXTpikvXtba2XppSetGECZMufVP3ywoLzSQkJF2aMDp69BgOHz7E3LkZl24jyycpLi4iN/dzEhOT+PGPHyYgIPCa6xMEtZwtbWBNbgEnCjsm2440DSAr3cTAhNAbXpfq5d9bou64q8d76WKq581P9exuUmZLSzOhoV+MSLiYt7PydzodPPfcH3C5nHzrW3eTljbr0m0DAgJuaMrolwfHXeuxGjZsBEuXrmDo0GG8/fYbvPnm31i9+idfXpUgqOJceQNrd5g5Zu44CjDcGM6K9FQGJd546V/Ub8q/r4mpnlfu+Xc3KTMwMOjS9V/k7fxTDsOHj8JgMAAGTCYTlZXll8r/evb8X3vtzxw5cgiAH//4kWts+8p8M2d+8SI4c+YcXnzxxv4tBMEdzBWNrNlh5mhBHQDDUsLJSjcxJOnmZ02J8u8hMdXzSqNGjelyUuaoUWP4y1/+yNe+9k2qq6txuZQuh6WdOSPjcDiw2+0XDtskXrruevb8V6164NL/OxwOSktLaGxswN8/gEOHDvK1r115KO2hh1bz4IM/ZfjwkezfvwdJGtrl+gXBnYoqm1izo4DD5zpKX0oKY8UME1Lytf9S7glR/jdh7NjxVFSUX5rqWVhY0CdTPT/44H0eeeQxVq/+Cb/97W94882/Eh+fdMVkzC+X48Wpnl//+n9dmup58Rj95VM9AYKCgnj22d/fUK6VK2/n6aef5P7778NgMPDkk08DHZMyZ8+ex/DhIxk9eizf+949KIrCQw89CkB29icEB/sxY8b8K9bn4+PDI4/8iObmZu69dxUhITfx561ez+rVD/LQQz/E5XKRmbmcqKjoKx7LRx75OX/4w2/R6/VERETws5893uPtCUJPFVc1sTbXzMEztQAMSQwla0Yqw1J6r/QvElM98e7PCYN3T/U8e/YMZWUFzJq1UO0oPSameqrLm/NfzF5a3czaXDP7T9cAMCghlKwZJoanhN/UeaS7muop9vz7IW/6uGJISAhTp95GbW3Xp3EUhP6oqKKRtz45xj65o/QHxoeQNcPECOOAmyr96yHKvx/ypsmY0dExbn+SC4KnKatt4ZM8M3tPVaMoYIoLJis9lVGp7i/9i0T5C4Ig9JGKuhY+zitkz4kqFGBgYihLp6YwemBEn+8EifIXBEFws6rzrXycZ2bXiSoUBZKjg8iaYWL+NJNqhzxF+QuCILhJtaWVT/IK2Xm8EkWBxKggstJNjB8SiUajUfWQpyh/QRCEXlZd38aneYXsPFaJS1FIiAzsKH0pCq2HvMclyt+Nbnaq58cff8TatR+i0+n41rc6hpFd7tixo7z00vP4+fkwbtwk7r13VY9yVlZW8swzT+F0OgD42c9+QXKysUfrev/9f1FXV8f99//wquvEVE+hv6utb+PT/ELyjlbidCnERQSQlW5i4tBojyn9i/pN+e/cco6CU9U9Wlar0+K6xlTP1KHRTJ87sEfrvNmpnnV1tfznP//m9dffwWaz8cAD9zFp0hR8fHwu3eb555/hN7/5LWPGDOXb374XWT7Vo2+mvv76X7jttjuZOXP2hdyv3PCoCau1neee+w0nThxj1qy5V10vpnoK/VldQzvr8gvZcaQCp0shdkAAy9ONTB4ag1brWaV/Ub8p/77m7qmeJ08eZ9SoMfj4+ODj40NCQhLnzp1h2LARQMegNLvdRkJCIhqNhsmTp3U6lmD79m3s27ebhx56lHfe+TvHjx/l2Wd/z4YN2VRVVbJ69YOXZt04nc4rXmAADh8+xN/+9ucrLrvrrq+Tnj7r0s9Wq41FizKZOHEyRUWFV2UQUz2F/uh8Yzvr8ovYfrgcp0shJtyf5Wkmpgz33NK/qN+U//S5A3u8l+6JUz1bWloIDLx8EmUAzc3NV1x/eTkFBARQXl52zXVNmTKVN974KwCHDx/k/Pk6HA4HeXk7uO++712asVNcXMgrr7zIM888f8XyY8aM7XaWTkhICJMnTyU7+5NO7o+Y6in0H5YmK9n5RXx+uAyHUyE6zJ9laUamjohB14MTKqmh35R/X3P3VM+OKZlfnLqytbX10tTJi9e3tV15fWdTMn19/UhKSubkyePo9XpGjBjN4cMHqaqqJCXFCHQcZ3/hhWd54omnrjrefz17/t3pb1M9nTY49paByr06AoMhOl3P4JUOPOywrtDL6putZO8qYtvBchxOF5GhfixLMzJ9ZKzXlP5Fap3AXQf8DZAAJ3CPLMvn1MjSU+6e6jls2Ahee+3PWK1W7HY7RUVmTKYv/rIJDAxCrzdQVlZKZORQ9uzJ5557On/Dd+bMObzyykvMnDmb+PgEXn31FSZNmgJ0FP9LLz3PCy+8TGxs3FXLXs+ef3f601RPRzt89k1/Sj6/7NfnX36U77Qz+3lrl7kE79TQYuOzXUVsPViG3eEiIuSL0tfrvKv0L1Jrz38ZgCzLaZIkzQZ+D2SplKXH3DnVMyIikttvv4sf/OC7uFwuVq16AF9fX/bv38uRI4e4557v8sgjP+dXv/olWi2MGzeJESNGUldXyx//+MJVn5SZPn0GzzzzFA8//BgxMTH88peP8sgjjwHw0ksvYLfbefrpJwFITk7ptamW/XGq55FXfa4sfgCXBvk9A4NX2klIu/rDA4J3amy1sX5XMVsOlGJzuBgQ4svS6UbSR8V5belfpNpUT0mS9LIsOyRJ+haQJstyl59TFFM9O3d5fofDwV/+8jI//OGDKqe6Pt441TP7m34UbjBc87rR37OS/mtbr21LTPXsnjvyN7XaWL+nmC37y7DanYQH+7J0Wgrpo+Mx6Huv9N312Ne21fFZ4WYemnmf5031vFD8bwMrgdu7u314eAB6vc5teaKiOj/+7A0u5rfb7fzwh/d7zf1xOuOZOnWcVw138/Xv/LrAYF+iom78Ox2dKbqwd+nuf09veb50p