{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import sys\n",
    "\n",
    "# Follow instructions here to get cvxopt working. --- painful!!! \n",
    "#https://stackoverflow.com/questions/46009925/how-to-install-cvxopt-on-on-windows-10-on-python-3-6\n",
    "from cvxopt import matrix, solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common code for questions 7-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training and testing data in pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    column_names = ['digit', 'intensity', 'symmetry']\n",
    "    sep = '\\s+'\n",
    "    features_train = pd.read_table('http://www.amlbook.com/data/zip/features.train', sep=sep, names=column_names)\n",
    "    features_test = pd.read_table('http://www.amlbook.com/data/zip/features.test', sep=sep, names=column_names)\n",
    "    return features_train, features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set output labels for classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_one_vs_all = dict(\n",
    "    {'zero_vs_all': 0,\n",
    "     'one_vs_all': 1,\n",
    "     'two_vs_all': 2,\n",
    "     'three_vs_all': 3,\n",
    "     'four_vs_all': 4,\n",
    "     'five_vs_all': 5,\n",
    "     'six_vs_all': 6,\n",
    "     'seven_vs_all': 7,\n",
    "     'eight_vs_all': 8,\n",
    "     'nine_vs_all': 9\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_one_vs_five = {'one_vs_five': [1,5]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create one-versus-all and one-versus-five dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_vs_all_dataframe(df, classifiers):\n",
    "    # add binary labels to dataframe\n",
    "    one_vs_all = pd.DataFrame(df, copy=True)\n",
    "    for class_label, digit in classifiers.items():\n",
    "        labels = one_vs_all.loc[one_vs_all['digit'] == digit, 'digit']\n",
    "        labels.loc[:] = 1.0\n",
    "        one_vs_all[class_label] = labels\n",
    "        \n",
    "    one_vs_all.fillna(-1.0, inplace=True)\n",
    "    return one_vs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_one_vs_all = create_one_vs_all_dataframe(features_train, classifiers_one_vs_all)\n",
    "features_test_one_vs_all = create_one_vs_all_dataframe(features_test, classifiers_one_vs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_vs_one_dataframe(df, classifiers):\n",
    "    # add binary labels to dataframe  \n",
    "    for class_label in classifiers.keys():\n",
    "        digits = classifiers[class_label]\n",
    "        one_vs_one = pd.DataFrame(df.loc[df['digit'].isin(digits),:], copy=True)\n",
    "        for digit in digits:\n",
    "            labels = one_vs_one.loc[one_vs_one['digit'] == digit, 'digit']\n",
    "            labels.loc[:] = 1.0\n",
    "            one_vs_one[class_label] = labels\n",
    "            break\n",
    "        \n",
    "    one_vs_one.fillna(-1.0, inplace=True)\n",
    "    return one_vs_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_one_vs_five = create_one_vs_one_dataframe(features_train, classifiers_one_vs_five)\n",
    "features_test_one_vs_five = create_one_vs_one_dataframe(features_test, classifiers_one_vs_five)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dataset (inputs / outputs) for a specific classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(df, class_label):\n",
    "    inputs = np.array(df.loc[:, ['intensity', 'symmetry']])\n",
    "    outputs = np.array(df.loc[:, class_label])\n",
    "    data = np.column_stack((inputs, outputs))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of regularized least-squares linear regression for classiﬁcation that minimizes:\n",
    "\n",
    "$$\\frac{1}{N}\\sum_{n=1}^{N}(\\textbf{w}^{T}\\textbf{z}_{n}-y_{n})^{2}+\\frac{\\lambda}{N}\\textbf{w}^{T}\\textbf{w}$$\n",
    "\n",
    "where $\\textbf{w}$ includes $w_{0}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \"\"\" Class that performs regularized least-squares linear regression for classification. \"\"\"\n",
    "    \n",
    "    def __init__(self, transform=False):\n",
    "        \"\"\" Create a Linear Regression Algorithm. \n",
    "        Args:\n",
    "        transform (bool): If True, apply a feature transform z = (1, x1, x2, x1.x2, x1^2, x2^2) to the inputs (x1, x2)\n",
    "                          Otherwise, use inputs as they are so z = (1, x1, x2)\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "    \n",
    "    def fit(self, inputs, outputs, llambda=1.0):    \n",
    "        \"\"\"Fit the training data using the regularized least-squares linear regression learning algorithm\n",
    "        Args:\n",
    "        inputs (np.ndarray): Inputs\n",
    "        outputs (np.ndarray): Outputs\n",
    "        llambda (float): Regularization parameter\n",
    "        Returns:\n",
    "        np.ndarray: Weights\n",
    "        \"\"\"      \n",
    "        # get inputs and outputs\n",
    "        Z = self.transform_inputs(inputs)\n",
    "        y = outputs\n",
    "        \n",
    "        # linear regression solution with regularization\n",
    "        Z_trans = np.transpose(Z)\n",
    "        normZ = np.matmul(Z_trans, Z)  \n",
    "        I = np.identity(np.size(normZ, axis=0))\n",
    "        weights = np.matmul(np.linalg.inv(np.add(normZ, llambda * I)), np.matmul(Z_trans, y))\n",
    "        return weights\n",
    "    \n",
    "    def binary_error(self, weights, inputs, outputs):    \n",
    "        \"\"\"Compute binary classification error of sample\n",
    "        Args:\n",
    "        weights (np.ndarray): Weights of hypothesis\n",
    "        inputs (np.ndarray): Inputs\n",
    "        outputs (np.ndarray): Outputs\n",
    "        Returns:\n",
    "        float: Binary classification error (fraction of misclassified points in the sample)\n",
    "        \"\"\"\n",
    "        Z = self.transform_inputs(inputs)\n",
    "        y = outputs\n",
    "        \n",
    "        g = [np.sign(np.dot(weights.T, z)) for z in Z]\n",
    "        return sum(g != y) / len(y)        \n",
    "         \n",
    "    # privates\n",
    "    def transform_inputs(self, inputs):\n",
    "        ones = np.ones(len(inputs)).reshape(len(inputs), 1)\n",
    "        x1 = inputs[:, 0].reshape(len(inputs), 1)\n",
    "        x2 = inputs[:, 1].reshape(len(inputs), 1)\n",
    "        \n",
    "        if self.transform:\n",
    "            return np.concatenate((ones, x1, x2, x1*x2, x1**2, x2**2), axis=1)\n",
    "        else:\n",
    "            return np.concatenate((ones, x1, x2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute in-sample and out-of-sample errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_out_sample_errors(classifiers, features_train, features_test=pd.DataFrame(), llambda=1.0, transform=False):\n",
    "    results = []\n",
    "    \n",
    "    for class_label in classifiers.keys():\n",
    "            # get training data\n",
    "            dataset_train = get_dataset(features_train, class_label)\n",
    "            inputs_train = dataset_train[:, 0:2]\n",
    "            outputs_train = dataset_train[:, 2]\n",
    "            \n",
    "            # fit the model\n",
    "            lr = LinearRegression(transform)\n",
    "            weights = lr.fit(inputs_train, outputs_train, llambda)\n",
    "            \n",
    "            # compute in-sample error\n",
    "            error_in_sample = lr.binary_error(weights, inputs_train, outputs_train)\n",
    "            \n",
    "            # get testing data\n",
    "            error_out_sample = None\n",
    "            if not features_test.empty:\n",
    "                dataset_test = get_dataset(features_test, class_label)\n",
    "                inputs_test = dataset_test[:, 0:2]\n",
    "                outputs_test = dataset_test[:, 2]\n",
    "                \n",
    "                # compute out-of-sample error\n",
    "                error_out_sample =  lr.binary_error(weights, inputs_test, outputs_test)\n",
    "            \n",
    "            # add to results\n",
    "            result = {'classifier': class_label,\n",
    "                      'transform': transform,\n",
    "                      'lambda': llambda,\n",
    "                      'ein': error_in_sample,\n",
    "                      'eout': error_out_sample}\n",
    "            results.append(result)\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_binary_errors(results, print_classifiers=None, print_errors='both'):   \n",
    "    if print_errors not in ['ein', 'eout', 'both']:\n",
    "        raise ValueError('\"print_errors\" must either \"ein\", \"eout\" or \"both\"')\n",
    "    \n",
    "    for result in results:\n",
    "        if isinstance(print_classifiers, list) and result['classifier'] not in print_classifiers:\n",
    "            continue\n",
    "        \n",
    "        if print_errors == 'ein':\n",
    "            print('For transform = {0} and λ = {1}, the \"{2}\" classifier in-sample error Ein = {3}'\n",
    "                  .format(result['transform'], result['lambda'], result['classifier'], round(result['ein'], 3)))\n",
    "        elif print_errors == 'eout':\n",
    "            print('For transform = {0} and λ = {1}, the \"{2}\" classifier in-sample error Eout = {3}'\n",
    "                  .format(result['transform'], result['lambda'], result['classifier'], round(result['eout'], 3)))\n",
    "        elif print_errors == 'both':\n",
    "            print('For transform = {0} and λ = {1}, the \"{2}\" classifier in-sample error Ein = {3} '\n",
    "                  'and the out-of-sample-error Eout = {4}'\n",
    "                  .format(result['transform'], result['lambda'], result['classifier'], \n",
    "                          round(result['ein'], 3), round(result['eout'], 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Compute in-sample error for 5-versus-all through to 9-versus-all classifier for $\\lambda$ = 1 without a feature transform $z = x = (1, x_{1}, x_{2})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = in_out_sample_errors(classifiers_one_vs_all, features_train_one_vs_all, llambda=1.0, transform=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For transform = False and λ = 1.0, the \"five_vs_all\" classifier in-sample error Ein = 0.076\n",
      "For transform = False and λ = 1.0, the \"six_vs_all\" classifier in-sample error Ein = 0.091\n",
      "For transform = False and λ = 1.0, the \"seven_vs_all\" classifier in-sample error Ein = 0.088\n",
      "For transform = False and λ = 1.0, the \"eight_vs_all\" classifier in-sample error Ein = 0.074\n",
      "For transform = False and λ = 1.0, the \"nine_vs_all\" classifier in-sample error Ein = 0.088\n"
     ]
    }
   ],
   "source": [
    "print_binary_errors(results, print_classifiers=['five_vs_all', \n",
    "                                                'six_vs_all', \n",
    "                                                'seven_vs_all', \n",
    "                                                'eight_vs_all', \n",
    "                                                'nine_vs_all'],\n",
    "                    print_errors='ein')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Compute out-of-sample error for 0-versus-all through to 4-versus-all classifier for $\\lambda$ = 1 with a feature transform $z = (1, x_{1}, x_{2}, x_{1}x_{2}, x_{1}^2, x_{2}^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = in_out_sample_errors(classifiers_one_vs_all, features_train_one_vs_all, features_test_one_vs_all, llambda=1.0, \n",
    "                               transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For transform = True and λ = 1.0, the \"zero_vs_all\" classifier in-sample error Eout = 0.107\n",
      "For transform = True and λ = 1.0, the \"one_vs_all\" classifier in-sample error Eout = 0.022\n",
      "For transform = True and λ = 1.0, the \"two_vs_all\" classifier in-sample error Eout = 0.099\n",
      "For transform = True and λ = 1.0, the \"three_vs_all\" classifier in-sample error Eout = 0.083\n",
      "For transform = True and λ = 1.0, the \"four_vs_all\" classifier in-sample error Eout = 0.1\n"
     ]
    }
   ],
   "source": [
    "print_binary_errors(results, print_classifiers=['zero_vs_all', \n",
    "                                                'one_vs_all', \n",
    "                                                'two_vs_all', \n",
    "                                                'three_vs_all', \n",
    "                                                'four_vs_all'],\n",
    "                    print_errors='eout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Compare the in-sample and out-of-sample errors for 0-versus-all through to 9-versus-all classifier for $\\lambda$ = 1 with and without the feature transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = in_out_sample_errors(classifiers_one_vs_all, features_train_one_vs_all, features_test_one_vs_all, llambda=1.0, \n",
    "                               transform=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For transform = False and λ = 1.0, the \"zero_vs_all\" classifier in-sample error Ein = 0.109 and the out-of-sample-error Eout = 0.115\n",
      "For transform = False and λ = 1.0, the \"one_vs_all\" classifier in-sample error Ein = 0.015 and the out-of-sample-error Eout = 0.022\n",
      "For transform = False and λ = 1.0, the \"two_vs_all\" classifier in-sample error Ein = 0.1 and the out-of-sample-error Eout = 0.099\n",
      "For transform = False and λ = 1.0, the \"three_vs_all\" classifier in-sample error Ein = 0.09 and the out-of-sample-error Eout = 0.083\n",
      "For transform = False and λ = 1.0, the \"four_vs_all\" classifier in-sample error Ein = 0.089 and the out-of-sample-error Eout = 0.1\n",
      "For transform = False and λ = 1.0, the \"five_vs_all\" classifier in-sample error Ein = 0.076 and the out-of-sample-error Eout = 0.08\n",
      "For transform = False and λ = 1.0, the \"six_vs_all\" classifier in-sample error Ein = 0.091 and the out-of-sample-error Eout = 0.085\n",
      "For transform = False and λ = 1.0, the \"seven_vs_all\" classifier in-sample error Ein = 0.088 and the out-of-sample-error Eout = 0.073\n",
      "For transform = False and λ = 1.0, the \"eight_vs_all\" classifier in-sample error Ein = 0.074 and the out-of-sample-error Eout = 0.083\n",
      "For transform = False and λ = 1.0, the \"nine_vs_all\" classifier in-sample error Ein = 0.088 and the out-of-sample-error Eout = 0.088\n"
     ]
    }
   ],
   "source": [
    "print_binary_errors(results, print_errors='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = in_out_sample_errors(classifiers_one_vs_all, features_train_one_vs_all, features_test_one_vs_all, llambda=1.0, \n",
    "                               transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For transform = True and λ = 1.0, the \"zero_vs_all\" classifier in-sample error Ein = 0.102 and the out-of-sample-error Eout = 0.107\n",
      "For transform = True and λ = 1.0, the \"one_vs_all\" classifier in-sample error Ein = 0.012 and the out-of-sample-error Eout = 0.022\n",
      "For transform = True and λ = 1.0, the \"two_vs_all\" classifier in-sample error Ein = 0.1 and the out-of-sample-error Eout = 0.099\n",
      "For transform = True and λ = 1.0, the \"three_vs_all\" classifier in-sample error Ein = 0.09 and the out-of-sample-error Eout = 0.083\n",
      "For transform = True and λ = 1.0, the \"four_vs_all\" classifier in-sample error Ein = 0.089 and the out-of-sample-error Eout = 0.1\n",
      "For transform = True and λ = 1.0, the \"five_vs_all\" classifier in-sample error Ein = 0.076 and the out-of-sample-error Eout = 0.079\n",
      "For transform = True and λ = 1.0, the \"six_vs_all\" classifier in-sample error Ein = 0.091 and the out-of-sample-error Eout = 0.085\n",
      "For transform = True and λ = 1.0, the \"seven_vs_all\" classifier in-sample error Ein = 0.088 and the out-of-sample-error Eout = 0.073\n",
      "For transform = True and λ = 1.0, the \"eight_vs_all\" classifier in-sample error Ein = 0.074 and the out-of-sample-error Eout = 0.083\n",
      "For transform = True and λ = 1.0, the \"nine_vs_all\" classifier in-sample error Ein = 0.088 and the out-of-sample-error Eout = 0.088\n"
     ]
    }
   ],
   "source": [
    "print_binary_errors(results, print_errors='both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Compare the in-sample and out-of-sample errors for 0-versus-all through to 9-versus-all classifier for λ = 1.0 and λ = 0.01 with feature transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = in_out_sample_errors(classifiers_one_vs_five, features_train_one_vs_five, features_test_one_vs_five, llambda=1.0, \n",
    "                               transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For transform = True and λ = 1.0, the \"one_vs_five\" classifier in-sample error Ein = 0.005 and the out-of-sample-error Eout = 0.026\n"
     ]
    }
   ],
   "source": [
    "print_binary_errors(results, print_errors='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = in_out_sample_errors(classifiers_one_vs_five, features_train_one_vs_five, features_test_one_vs_five, llambda=0.01, \n",
    "                               transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For transform = True and λ = 0.01, the \"one_vs_five\" classifier in-sample error Ein = 0.004 and the out-of-sample-error Eout = 0.028\n"
     ]
    }
   ],
   "source": [
    "print_binary_errors(results, print_errors='both')"