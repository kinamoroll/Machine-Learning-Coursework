
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from math import exp, sqrt\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimize function E(u, v) = (u$e^{v}$-2v$e^{-u}$)$^{2}$\n",
    "<br>\n",
    "Derivatives:\n",
    "<br>\n",
    "$\\frac{\\partial E}{\\partial u}$ = 2 (u$e^{v}$-2v$e^{-u}$)($e^{v}$+2v$e^{-u}$)\n",
    "<br>\n",
    "$\\frac{\\partial E}{\\partial v}$ = 2 (u$e^{v}$-2v$e^{-u}$)(u$e^{v}$-2$e^{-u}$)\n",
    "<br>\n",
    "Start at (u,v) = (1,1) and with learning rate $\\eta$=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Error:\n",
    "    \"\"\" Error function class\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def evaluate(u, v):\n",
    "        \"\"\"Evaluate the function\n",
    "        Args:\n",
    "        u (float): u coordinate\n",
    "        v (float): v coordinate\n",
    "        Returns:\n",
    "        The function value (float)\n",
    "        \"\"\"\n",
    "        return (u*exp(v)-2*v*exp(-u))**2\n",
    "    \n",
    "    @staticmethod\n",
    "    def dEdu(u, v):\n",
    "        \"\"\"Evaluate the partial derivative dE/du of the function\n",
    "        Args:\n",
    "        u (float): u coordinate\n",
    "        v (float): v coordinate\n",
    "        Returns:\n",
    "        The partial derivative dE/du (float)\n",
    "        \"\"\"\n",
    "        return 2*(u*exp(v)-2*v*exp(-u))*(exp(v)+2*v*exp(-u))\n",
    "    \n",
    "    @staticmethod\n",
    "    def dEdv(u, v):\n",
    "        \"\"\"Evaluate the partial derivative dE/dv of the function\n",
    "        Args:\n",
    "        u (float): u coordinate\n",
    "        v (float): v coordinate\n",
    "        Returns:\n",
    "        The partial derivative dE/dv (float)\n",
    "        \"\"\"\n",
    "        return 2*(u*exp(v)-2*v*exp(-u))*(u*exp(v)-2*exp(-u))\n",
    "    \n",
    "    @staticmethod\n",
    "    def gradient(u, v):\n",
    "        \"\"\"Evaluate the gradient of the function\n",
    "        Args:\n",
    "        u (float): u coordinate\n",
    "        v (float): v coordinate\n",
    "        Returns:\n",
    "        The function gradient value (float)\n",
    "        \"\"\"\n",
    "        return np.array([Error.dEdu(u,v), Error.dEdv(u,v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescent:\n",
    "    \"\"\"Gradient descent class\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def minimize(f, initial_guess=np.array([1.0, 1.0]), learning_rate = 0.1, conv_error=10**-14, max_iterations=20):\n",
    "        \"\"\"Perform gradient descent minimization\n",
    "        Args:\n",
    "        f (function): Error function to minimize\n",
    "        initial_guess (numpy ndarray): Initial guess\n",
    "        learning_rate (float): Learning rate\n",
    "        conv_error (float): Error function value below which convergence is assumed \n",
    "        max_iterations (int): Maximum number of iterations\n",
    "        Returns:\n",
    "        Tuple(error, error_val, num_iterations) (Tuple(numpy ndarray, float, int): Tuple of error, \n",
    "        error function value at minimum, number of iterations\n",
    "        \"\"\"\n",
    "        prev_error = np.array(initial_guess) \n",
    "        num_iterations = 0\n",
    "        for i in range(0, max_iterations):\n",
    "            error = prev_error - learning_rate * f.gradient(prev_error[0], prev_error[1])\n",
    "            error_val = Error.evaluate(error[0], error[1])\n",
    "            prev_error =  error\n",
    "            num_iterations += 1\n",
    "            if error_val < conv_error:\n",
    "                break\n",
    "        return error, error_val, num_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final (u, v) =  [0.04473629 0.02395871]\n",
      "Number of iterations needed =  10\n"
     ]
    }
   ],
   "source": [
    "error, error_val, num_iterations = GradientDescent.minimize(Error)\n",
    "print('Final (u, v) = ', error)\n",
    "print('Number of iterations needed = ', num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoordinateDescent:\n",
    "    \"\"\"Coordinate descent class\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def minimize(f, initial_guess=np.array([1.0, 1.0]), learning_rate = 0.1, max_iterations=15):\n",
    "        \"\"\"Perform coordinate descent minimization\n",
    "        Args:\n",
    "        f (function): Error function to minimize\n",
    "        initial_guess (numpy ndarray): Initial guess\n",
    "        learning_rate (float): Learning rate\n",
    "        max_iterations (int): Maximum number of iterations\n",
    "        Returns:\n",
    "        Tuple(error, error_val) (Tuple(numpy ndarray, float): Tuple of error, error function value at minimum\n",
    "        \"\"\"\n",
    "        prev_error = np.array(initial_guess) \n",
    "        error = np.zeros(2, dtype=float)\n",
    "        for i in range(0, max_iterations):\n",
    "            error[0] = prev_error[0] - learning_rate * f.dEdu(prev_error[0], prev_error[1]) # 1st step\n",
    "            prev_error[0] = error[0]\n",
    "            error[1] = prev_error[1] - learning_rate * f.dEdv(prev_error[0], prev_error[1]) # 2nd step\n",
    "            prev_error[1] = error[1]\n",